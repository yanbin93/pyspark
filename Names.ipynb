{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#!/usr/bin/env python\n",
    "# -*- coding:utf-8 -*-\n",
    "__author__ = \"yan bin\"\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.pipeline import Pipeline,PipelineModel\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *  \n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit,CrossValidator\n",
    "from pandas import *\n",
    "import matplotlib as mpl\n",
    "import time\n",
    "from numpy import arange,logspace\n",
    "import sys\n",
    "mpl.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def myInt(x):\n",
    "    try:\n",
    "        return int(x)\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "def map_extract(element):\n",
    "    file_path, content = element\n",
    "    year = file_path[-8:-4]\n",
    "    return [(year, i) for i in content.split(\"\\r\\n\") if i]\n",
    "\n",
    "class spark:\n",
    "    __spark = 0\n",
    "    __sc = 0\n",
    "\n",
    "\n",
    "    def __init__(self, master=\"local\", appName=\"sparkDemo\"):\n",
    "        conf = (SparkConf().setAppName(appName)\n",
    "                .setMaster(master))\n",
    "        self.__spark = (SparkSession.builder\n",
    "                .config(conf=conf)\n",
    "                .enableHiveSupport()\n",
    "                .getOrCreate())\n",
    "        self.__sc = self.__spark.sparkContext\n",
    "\n",
    "\n",
    "    def getContext(self):\n",
    "        return (self.__spark, self.__sc)\n",
    "\n",
    "\n",
    "    def getJson(self, inputPath):\n",
    "        spark, sc = self.getContext()\n",
    "        rawData = spark.read.json(inputPath)\n",
    "        ratingDf = (rawData.select(rawData.reviewerID.alias(\"user\"),\n",
    "                                   rawData.asin.alias(\"item\"),\n",
    "                                   rawData.overall.alias(\"rating\")))\n",
    "        return ratingDf\n",
    "    \n",
    "    def getText(self, inputPath):\n",
    "        spark, sc = self.getContext()\n",
    "        rawData = sc.textFile(inputPath)\n",
    "        rawData = (rawData.map(lambda x:x.split(\"::\"))\n",
    "                            .map(lambda x:(myInt(x[0]),myInt(x[1]),myInt(x[2]),myInt(x[3]))))\n",
    "        ratingDf =spark.createDataFrame(rawData,(\"user\",\"item\",\"rating\",\"timestamp\"))\n",
    "        return ratingDf.na.drop() \n",
    "    \n",
    "                 \n",
    "    def getDoc(self,inputPath):\n",
    "        spark, sc = self.getContext()\n",
    "        res=sc.wholeTextFiles(inputPath,minPartitions=40)\n",
    "        return res\n",
    "    \n",
    "        \n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    start = time.time()\n",
    "    s = spark(appName=\"test\",master=\"local[4]\")\n",
    "    spark, sc = s.getContext()\n",
    "    inputPath=\"data/names\"\n",
    "    res = s.getDoc(inputPath)\n",
    "    from operator import add\n",
    "#     newresw = res.map(lambda x:[(x[0][-8:-4],int(i.split(\",\")[-1])) for i in x[1].split(\"\\r\\n\") if i])\\\n",
    "#     .flatMap(lambda x:x).reduceByKey(add).sortByKey()\n",
    "    newres = res.map(lambda x: (x[0][-8:-4],[int(i.split(\",\")[-1]) for i in x[1].split(\"\\r\\n\") if i]))\\\n",
    "    .flatMapValues(lambda x:x).reduceByKey(add).sortByKey()\n",
    "#     print (newres.take(5))\n",
    "#     print (newresw.take(5))\n",
    "    newres.collect()\n",
    "    \n",
    "    sc.stop()\n",
    "    spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'setCallSite'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-3f17e3e88a30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'year'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'birth'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m             \u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'year'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m ax = data.plot(x=['year'], y=['birth'], \n\u001b[1;32m      4\u001b[0m                     \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'US Baby Birth Data from 1897 to 2014'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yanbin/hadoop-2.6/spark/python/pyspark/rdd.pyc\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    806\u001b[0m             \u001b[0mto\u001b[0m \u001b[0mbe\u001b[0m \u001b[0msmall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mall\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mloaded\u001b[0m \u001b[0minto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m         \"\"\"\n\u001b[0;32m--> 808\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m             \u001b[0mport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yanbin/hadoop-2.6/spark/python/pyspark/traceback_utils.pyc\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark_stack_depth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetCallSite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_site\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark_stack_depth\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'setCallSite'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.DataFrame.from_records(newres.collect(), columns=['year', 'birth'])\\\n",
    "             .sort(columns=['year'], ascending=True)\n",
    "ax = data.plot(x=['year'], y=['birth'], \n",
    "                    figsize=(20, 6), \n",
    "                    title='US Baby Birth Data from 1897 to 2014', \n",
    "                    linewidth=3)\n",
    "ax.set_axis_bgcolor('white')\n",
    "ax.grid(color='gray', alpha=0.2, axis='y')\n",
    "sc.stop()\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
